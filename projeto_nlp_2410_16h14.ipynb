{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# ------- FUNÇÕES (brevemente comentadas)\n",
    "\n",
    "# todo o pré processamento, com exceção da vetorização\n",
    "def text_preproc(dataframe, series_name, target, pos_label):\n",
    "    # remoção de stop words\n",
    "    dataframe[series_name] = dataframe[series_name].apply(lambda x:\n",
    "                                                          [token for token in nlp(x) if not token.is_stop])\n",
    "    # remoção de pontuação\n",
    "    dataframe[series_name] = dataframe[series_name].apply(lambda x:\n",
    "                                                          [token for token in x if not token.is_punct])\n",
    "    # lemmatização\n",
    "    dataframe[series_name] = dataframe[series_name].apply(lambda x:\n",
    "                                                          [token.lemma_ for token in x])\n",
    "    # passando tokens para formato minúsculo\n",
    "    dataframe[series_name] = dataframe[series_name].apply(lambda x:\n",
    "                                                          [token.lower() for token in x])\n",
    "    # transformando listas de tokens em strings (para vetorização)\n",
    "    dataframe[series_name] = dataframe[series_name].apply(lambda x: ' '.join(x))\n",
    "    # binarizando alvo\n",
    "    dataframe[target] = dataframe[target].apply(lambda x: int(x == pos_label))\n",
    "\n",
    "# obtenção da acurácia, com validação cruzada, sem otimização\n",
    "def simple_acc(mdl, split_dicti):\n",
    "    \n",
    "    accuracy_list = []\n",
    "    accuracy_list_overfit = []\n",
    "    \n",
    "    for key in split_dicti.keys(): # para cada fold (cada um é armazenado em dicionário)\n",
    "\n",
    "        data = split_dicti[key] # acessando key cujo valor é um dicionário, contendo \n",
    "                                # X_train, X_test, y_train, y_test\n",
    "\n",
    "        mdl.fit(data['X_train'], data['y_train'])\n",
    "\n",
    "        y_pred = mdl.predict(data['X_test'])  \n",
    "        y_pred_train = mdl.predict(data['X_train']) # para obtenção da métrica para porção de treino, \n",
    "                                                    # a fim de calcular o overfit\n",
    "\n",
    "        accuracy_list_overfit.append(accuracy_score(y_true = data['y_train'], y_pred = y_pred_train))\n",
    "        accuracy_list.append(accuracy_score(y_true = data['y_test'], y_pred = y_pred))\n",
    "    \n",
    "    # este 'retorno' é interpretado pela próxima função\n",
    "    return score_mean_std_overfit(accuracy_list, accuracy_list_overfit)\n",
    "\n",
    "# função para obter média, desvio padrão e overfit para diferentes métricas ('chamada' pela anterior)\n",
    "def score_mean_std_overfit(test, train):\n",
    "    return {'test_avg':np.mean(test), 'test_std':np.std(test), \n",
    "            'overfit_avg':np.mean([i[0] - i[1] for i in zip(train, test)])}\n",
    "\n",
    "# obtenção de splits de treino e teste (vetorizando-os)\n",
    "def get_folds(x, y, folds, seed):\n",
    "    # criando lista de listas com indexes de treino e teste, de acordo com KFold\n",
    "    kf = KFold(n_splits = folds, shuffle = True, random_state = seed)\n",
    "    split_index_list = [[train_index.tolist(), test_index.tolist()]\\\n",
    "                        for train_index, test_index in kf.split(x, y)]\n",
    "    # vetorizando cada split de treino e teste\n",
    "    count = 0\n",
    "    dicti = {}\n",
    "    for n in range(len(split_index_list)): # <- percorre lista de listas (contendo índices de treino e \n",
    "                                                                          # teste para para cada fold)\n",
    "        train_indexes = split_index_list[n][0] # variável contendo índices de treino\n",
    "        test_indexes = split_index_list[n][1] # variável contendo índices de teste\n",
    "\n",
    "        X_train = x.iloc[train_indexes] # declarando X_train, X_test, y_train, y_test\n",
    "        X_test = x.iloc[test_indexes]\n",
    "        y_train = y.iloc[train_indexes]\n",
    "        y_test = y.iloc[test_indexes]\n",
    "\n",
    "        vect = TfidfVectorizer()\n",
    "        X_train = vect.fit_transform(X_train) # ajuste aos mesmos e transformação dos dados de treino\n",
    "        X_test = vect.transform(X_test)       # dados de teste com este vetorizador ajustado ao treino\n",
    "\n",
    "        dicti[str(count)] = {'X_train':X_train, 'X_test':X_test, 'y_train':y_train, 'y_test':y_test}\n",
    "        count += 1\n",
    "        \n",
    "    return dicti\n",
    "\n",
    "# obtenção de métricas para combinações de hiperparâmetros (para um 'par' de treino e teste)\n",
    "def single_fold_tuning(partition, combo_dict):\n",
    "    \n",
    "    lista = []\n",
    "    for key in combo_dict:  \n",
    "        # verbosidade\n",
    "        clear_output()\n",
    "        print(key, '/', len(combo_dict) - 1)\n",
    "\n",
    "        combo = combo_dict[key]['params']\n",
    "        c = combo['C']\n",
    "        g = combo['gamma']\n",
    "        k = combo['kernel']\n",
    "\n",
    "        svc = SVC(C = c, gamma = g, kernel = k)\n",
    "        svc.fit(partition['X_train'], partition['y_train'])\n",
    "\n",
    "        lista.append([str(str(c) + ',' + str(g) + ',' + str(k)), accuracy_score(y_true = partition['y_test'],\n",
    "                                              y_pred = svc.predict(partition['X_test']))])\n",
    "    \n",
    "    return lista\n",
    "\n",
    "df = pd.read_csv('pycoders_reviews.tsv', sep = '\\t')\n",
    "nlp = en_core_web_sm.load()\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# em virtude do tempo de duração de alguns dos processos envolvidos neste projeto, a maior parte destes \n",
    "# teve seus resultados armazenados em arquivos '.pkl', todo o código envolvido está escrito no notebook, \n",
    "# como comentário, todavia, apenas as linhas que carregam tais arquivos estão escritas como código\n",
    "\n",
    "# neste projeto, consideramos os seguintes modelos: 'MultinomialNB', 'LogisticRegression', 'SVC'; por quê ?\n",
    "# referências:\n",
    "# https://monkeylearn.com/blog/sentiment-analysis-machine-learning/#:~:text=Naive%20Bayes%20is%20a%20fairly,be%20considered%20positive%20or%20negative.&text=Basically%2C%20Naive%20Bayes%20calculates%20words%20against%20each%20other.\n",
    "# https://theappsolutions.com/blog/development/sentiment-analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    0.509891\n",
       "pos    0.490109\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# balanceamento no dataframe original\n",
    "df['label'].value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9200 entries, 0 to 9199\n",
      "Data columns (total 2 columns):\n",
      "label     9200 non-null object\n",
      "review    9200 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 143.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# verificando consistência dos dados\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg    0.503995\n",
      "pos    0.496005\n",
      "Name: label, dtype: float64\n",
      "neg    0.521682\n",
      "pos    0.478318\n",
      "Name: label, dtype: float64\n",
      "\n",
      "neg    0.52242\n",
      "pos    0.47758\n",
      "Name: label, dtype: float64\n",
      "pos    0.515161\n",
      "neg    0.484839\n",
      "Name: label, dtype: float64\n",
      "\n",
      "neg    0.503261\n",
      "pos    0.496739\n",
      "Name: label, dtype: float64\n",
      "neg    0.523157\n",
      "pos    0.476843\n",
      "Name: label, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# posteriormente, será feita validação cruzada(random_state = seed), nesta célula, 'reproduzo' os splits,\n",
    "# analisando o balanceamento de cada um\n",
    "kf = KFold(n_splits = 3, shuffle = True, random_state = seed)\n",
    "split_index_list = [[train_index.tolist(), test_index.tolist()]\\\n",
    "                    for train_index, test_index in kf.split(df['review'], df['label'])]\n",
    "\n",
    "for n in range(len(split_index_list)):                                                                     \n",
    "    print(df['label'].iloc[split_index_list[n][0]].value_counts(1))\n",
    "    print(df['label'].iloc[split_index_list[n][1]].value_counts(1))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pré processando base inteira(operações 'independentes', como remoção de stop words, lemmatização ...)\n",
    "# text_preproc(df, 'review', 'label', 'pos')\n",
    "# pickle.dump(df, open('full_pre_proc_df.pkl', 'wb'))\n",
    "\n",
    "# validação cruzada com 3 folds, as variáveis explicativas são transformadas com vetorizadores separados\n",
    "# cada vetorizador é ajustado aos dados de treino, depois este transforma dados de treino e teste,\n",
    "# tinha a intenção de usar 5 folds, mas a otimização do SVC é muito lenta(na minha opinião)\n",
    "\n",
    "# como planejo otimizar hiperparâmetros de um dos modelos, além da necessidade de vetorizar cada\n",
    "# split de teste com objeto ajustado ao split de treino, opto por implementar a validação cruzada de uma\n",
    "# forma diferente(que me permitisse entender melhor o que acontece); a função get_folds() retorna um dicionário,\n",
    "# este que possuirá uma key para cada fold solicitado, cada uma destas keys possuirá como valor, um dicionário\n",
    "# com keys 'X_train', 'X_test', 'y_train', 'y_test', implementando este processo, faço a vetorização de treino\n",
    "# e teste com vetorizador ajustado ao split de treino, os splits retornados estão completamente pré processados\n",
    "# esta organização permite também realizar a otimização por fold individual, para que não precisasse ficar \n",
    "# com a máquina rodando ininterruptamente desde o início até o fim da mesma\n",
    "\n",
    "# split_dict = get_folds(df['review'], df['label'], 3, seed)\n",
    "# pickle.dump(split_dict, open('full_split_dictionary.pkl', 'wb'))\n",
    "\n",
    "df = pickle.load(open('full_pre_proc_df.pkl', 'rb'))\n",
    "split_dict = pickle.load(open('full_split_dictionary.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtendo acurácia de regressão logística e naive bayes (validação cruzada de 3 folds), os dicionários\n",
    "# retornados serão utilizados para a confecção de um dataframe que consolidará informações sobre as \n",
    "# performances de todos os modelos testados\n",
    "\n",
    "# lr_report = simple_acc(LogisticRegression(), split_dict)\n",
    "# lr_report['model'] = 'LogisticRegression'\n",
    "\n",
    "# mnb_report = simple_acc(MultinomialNB(), split_dict)\n",
    "# mnb_report['model'] = 'MultinomialNB'\n",
    "\n",
    "# pickle.dump(lr_report, open('lr_report.pkl', 'wb'))\n",
    "# pickle.dump(mnb_report, open('mnb_report.pkl', 'wb'))\n",
    "\n",
    "lr_report = pickle.load(open('lr_report.pkl', 'rb'))\n",
    "mnb_report = pickle.load(open('mnb_report.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando dicionário contendo as possíveis combinações de hiperparâmetros do SVC (otimização)\n",
    "\n",
    "combo_dict = {}\n",
    "combo_count = 0\n",
    "\n",
    "for c in [0.1, 1, 10, 100]:                     # valores testados para parâmetro: C\n",
    "    for g in [1, 0.1, 0.01, 0.001]:             #                //              : gamma\n",
    "        for k in ['rbf', 'poly', 'sigmoid']:    #                //              : kernel\n",
    "            \n",
    "            combo_dict[combo_count] = {'params':{'C':c, 'gamma':g, 'kernel':k}}\n",
    "            combo_count += 1\n",
    "            \n",
    "# será obtida a métrica de cada combinação para cada fold (para que possamos realizar a otimização em momentos\n",
    "# distintos), por exemplo, no caso de 3 folds, podemos obter a métrica de cada uma das 48 combinações de \n",
    "# hiperparâmteros para o primeiro fold, agora estamos diante de um dicionário contendo um valor para cada \n",
    "# combinação, em seguida, repetimos o processo com o segundo fold, agora, dois dicionários, considerando estes, \n",
    "# temos duas métricas para cada combinação, obtemos métricas para cada combinação em cada fold (número \n",
    "# arbitrário) finalmente, inserimos todas as combinações e scores em um dataframe, para 3 folds, este \n",
    "# terá, para cada possível combinação de hiperparâmetros, 3 métricas, assim sendo, ao realizar um groupby,\n",
    "# obtemos a média das métricas para determinada combinação, entre os 3 folds, em seguida, buscamos pelo\n",
    "# valor de score mais alto e consultamos a combinação que nos levou a este, finalizando a otimização\n",
    "\n",
    "# não rodar 'single_fold_tuning()' para vários folds em uma mesma célula (verbosidade, além de derrotar o \n",
    "# propósito; o motivo da otimização ter sido realizada desta forma foi (falta de paciência)\n",
    "# eu não querer separar x período de tempo contínuo do dia para deixar o computador trabalhando, então dividi\n",
    "# em 3 * (x/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold1_list = single_fold_tuning(split_dict['0'], combo_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(fold1_list, open('fold1_list.pkl', 'wb'))\n",
    "fold1_list = pickle.load(open('fold1_list.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold2_list = single_fold_tuning(split_dict['1'], combo_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(fold2_list, open('fold2_list.pkl', 'wb'))\n",
    "fold2_list = pickle.load(open('fold2_list.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold3_list = single_fold_tuning(split_dict['2'], combo_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(fold3_list, open('fold3_list.pkl', 'wb'))\n",
    "fold3_list = pickle.load(open('fold3_list.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1,1,rbf</th>\n",
       "      <td>0.848043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            score\n",
       "params           \n",
       "1,1,rbf  0.848043"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_data = fold1_list + fold2_list + fold3_list\n",
    "tuning_df = pd.DataFrame(tuning_data, columns = ['params', 'score'])\n",
    "tuning_df.groupby('params').mean().sort_values('score', ascending = False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1,1,rbf</td>\n",
       "      <td>0.852951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1,1,rbf</td>\n",
       "      <td>0.848060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1,1,rbf</td>\n",
       "      <td>0.843118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      params     score\n",
       "12   1,1,rbf  0.852951\n",
       "60   1,1,rbf  0.848060\n",
       "108  1,1,rbf  0.843118"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_df.loc[tuning_df.params == '1,1,rbf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concluímos que o conjunto de hiperparâmetros ideal para o SVC é C = 1, gamma = 1, kernel = 'rbf'\n",
    "# prosseguimos para a obtenção dos dados referentes á perfomance de um modelo com estes hiperparâmetros\n",
    "\n",
    "# svc_report = simple_acc(SVC(C = 1, gamma = 1, kernel = 'rbf'), split_dict)\n",
    "# svc_report['model'] = 'SVC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(svc_report, open('svc_report.pkl', 'wb'))\n",
    "svc_report = pickle.load(open('svc_report.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_data = [[svc_report[key] for key in svc_report], [mnb_report[key] for key in mnb_report],\n",
    "                   [lr_report[key] for key in lr_report]]\n",
    "final_report = pd.DataFrame(performance_data, columns = ['test_avg', 'test_std', 'overfit_avg', 'model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_avg</th>\n",
       "      <th>test_std</th>\n",
       "      <th>overfit_avg</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.848043</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>0.146631</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.823479</td>\n",
       "      <td>0.013997</td>\n",
       "      <td>0.107717</td>\n",
       "      <td>MultinomialNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.842065</td>\n",
       "      <td>0.004337</td>\n",
       "      <td>0.091142</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_avg  test_std  overfit_avg               model\n",
       "0  0.848043  0.004014     0.146631                 SVC\n",
       "1  0.823479  0.013997     0.107717       MultinomialNB\n",
       "2  0.842065  0.004337     0.091142  LogisticRegression"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paticularmente, optaria pela regressão logística, foi a segunda métrica mais alta, entretanto, não ficou muito\n",
    "# abaixo da primeira, apresentou o overfit mais baixo, este, por sua vez, é significativamente mais baixo que\n",
    "# os demais, já seu desvio padrão, se comporta de forma semelhante à métrica de teste, é a segunda mais alta,\n",
    "# mas não fica muito abaixo da primeira colocada (neste caso, quanto menor melhor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partimos para o pré processamento da base inteira, a fim de treinar um modelo para avaliação, á partir da\n",
    "# base escondida\n",
    "\n",
    "# vetorizando variáveis explicativas\n",
    "# vect = TfidfVectorizer()\n",
    "# X = vect.fit_transform(df['review']) \n",
    "\n",
    "# ajustando regressão logística\n",
    "# lr = LogisticRegression()\n",
    "# lr.fit(X, df['label'])\n",
    "\n",
    "# salvando modelo\n",
    "# pickle.dump(lr, open('fnl_mdl.pkl', 'wb'))\n",
    "\n",
    "# FIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
